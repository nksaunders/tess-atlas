{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESS Atlas fit for TOI {{{TOINUMBER}}}\n",
    "\n",
    "**Version: {{{VERSIONNUMBER}}}**\n",
    "\n",
    "**Note: This notebook was automatically generated as part of the TESS Atlas project. More information can be found on GitHub:** [github.com/dfm/tess-atlas](https://github.com/dfm/tess-atlas)\n",
    "\n",
    "In this notebook, we do a quicklook fit for the parameters of the TESS Objects of Interest (TOI) in the system number {{{TOINUMBER}}}.\n",
    "To do this fit, we use the [exoplanet](https://exoplanet.dfm.io) library and you can find more information about that project at [exoplanet.dfm.io](https://exoplanet.dfm.io).\n",
    "\n",
    "From here, you can scroll down and take a look at the fit results, or you can:\n",
    "\n",
    "- [open the notebook in Google Colab to run the fit yourself](https://colab.research.google.com/github/dfm/tess-atlas/blob/master/notebooks/{{{VERSIONNUMBER}}}/toi-{{{TOINUMBER}}}.ipynb),\n",
    "- [view the notebook on GitHub](https://github.com/dfm/tess-atlas/blob/master/notebooks/{{{VERSIONNUMBER}}}/toi-{{{TOINUMBER}}}.ipynb), or\n",
    "- [download the notebook](https://github.com/dfm/tess-atlas/raw/master/notebooks/{{{VERSIONNUMBER}}}/toi-{{{TOINUMBER}}}.ipynb).\n",
    "\n",
    "## Caveats\n",
    "\n",
    "There are many caveats associated with this relatively simple \"quicklook\" type of analysis that should be kept in mind.\n",
    "Here are some of the main things that come to mind:\n",
    "\n",
    "1. The orbits that we fit are constrained to be *circular*. One major effect of this approximation is that the fit will significantly overestimate the confidence of the impact parameter constraint, so the results for impact parameter shouldn't be taken too seriously. \n",
    "\n",
    "2. Transit timing variations, correlated noise, and (probably) your favorite systematics are ignored. Sorry!\n",
    "\n",
    "3. This notebook was generated automatically without human intervention. Use at your own risk!\n",
    "\n",
    "## Getting started\n",
    "\n",
    "To get going, we'll need to make out plots show up inline and install a few packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "!pip install -q -U lightkurve fbpca exoplanet corner pymc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll set up the plotting styles and do all of the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "rcParams[\"font.size\"] = 16\n",
    "rcParams[\"text.usetex\"] = False\n",
    "rcParams[\"font.family\"] = [\"sans-serif\"]\n",
    "rcParams[\"font.sans-serif\"] = [\"cmss10\"]\n",
    "rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import corner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pymc3 as pm\n",
    "import exoplanet as xo\n",
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data & de-trending\n",
    "\n",
    "Next, we grab the TOI list from [ExoFOP](https://exofop.ipac.caltech.edu/tess/) to get the information about the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toi_num = 144\n",
    "\n",
    "# Get the table of TOI info from ExoFOP\n",
    "tois = pd.read_csv(\"https://exofop.ipac.caltech.edu/tess/download_toi.php?sort=toi&output=csv\")\n",
    "\n",
    "# Select all of the rows in the TOI table that are associated with this target\n",
    "toi = tois[tois[\"TOI\"] == toi_num + 0.01].iloc[0]\n",
    "tic = toi['TIC ID']\n",
    "tois = tois[tois[\"TIC ID\"] == tic].sort_values(\"TOI\")\n",
    "\n",
    "# Extract the planet periods\n",
    "periods = np.array(tois[\"Period (days)\"], dtype=float)\n",
    "\n",
    "# Convert the phase to TBJD from BJD\n",
    "t0s = np.array(tois[\"Epoch (BJD)\"], dtype=float) - 2457000\n",
    "\n",
    "# Convert the depth to parts per thousand from parts per million\n",
    "depths = 1e-3 * np.array(tois[\"Depth (ppm)\"], dtype=float)\n",
    "\n",
    "# Convert the duration to days from hours\n",
    "durations = np.array(tois[\"Duration (hours)\"], dtype=float) / 24.0\n",
    "\n",
    "# Extract the stellar radius from the table\n",
    "toi_r_star = toi['Stellar Radius (R_Sun)']\n",
    "toi_r_star_err = toi['Stellar Radius (R_Sun) err']\n",
    "has_r_star = True\n",
    "\n",
    "# If there is no entry in the table (does this ever happen?)\n",
    "if not (np.isfinite(toi_r_star) and np.isfinite(toi_r_star_err)):\n",
    "    toi_r_star = 1.0\n",
    "    toi_r_star_err = 0.0\n",
    "    has_r_star = False\n",
    "\n",
    "# These are the letters that will be used to identify each candidate\n",
    "# (are we being a bit optimistic?)\n",
    "letters = \"bcdefghijklmnopqrstuvwxyz\"[:len(periods)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the [lightkurve](https://docs.lightkurve.org) library to download and de-trend the time series using [pixel-level decorrelation (PLD)](https://docs.lightkurve.org/api/lightkurve.correctors.PLDCorrector.html).\n",
    "We read in target pixel files (TPFs) for each of the campaigns in which TOI {{{TOINUMBER}}} was observed.\n",
    "To remove systematic noise, we mask out known transits and perform second order PLD. The noise-corrected light curves are stitched together to create a single contiguous light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the target pixel files\n",
    "sr = lk.search_targetpixelfile('TIC %i' % tic)\n",
    "tpf_collection = sr.download_all()\n",
    "\n",
    "# Extract the exposure time associated with the TPF\n",
    "hdr = tpf_collection[0].hdu[1].header\n",
    "texp = hdr[\"FRAMETIM\"] * hdr[\"NUM_FRM\"]\n",
    "texp /= 60.0 * 60.0 * 24.0\n",
    "\n",
    "# This function can be used to estimate which data points are in transit\n",
    "# for known phase, period, and duration\n",
    "def get_transit_mask(t, t0, period, duration):\n",
    "    hp = 0.5*period\n",
    "    return np.abs((t-t0+hp) % period - hp) < 0.5*duration\n",
    "\n",
    "# Run PLD on each TPF to extract the light curves\n",
    "lc_collection = []\n",
    "for tpf in tpf_collection:\n",
    "    mask = np.zeros_like(tpf.time, dtype=bool)\n",
    "    for i in range(len(periods)):\n",
    "        mask |= get_transit_mask(tpf.time, t0s[i], periods[i], 5*durations[i])\n",
    "    pld = tpf.to_corrector(\"pld\")\n",
    "    lc = pld.correct(aperture_mask=\"pipeline\", cadence_mask=~mask, use_gp=False, pld_order=2)\n",
    "    lc_collection.append(lc.normalize())\n",
    "\n",
    "# Normalize and stitch the sectors\n",
    "lc = lc_collection[0]\n",
    "if len(lc_collection) > 1:\n",
    "    lc = lc.append([next_lc for next_lc in lc_collection[1:]])\n",
    "lc = lc.remove_outliers()\n",
    "    \n",
    "lc.scatter();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stellar variability\n",
    "\n",
    "Next up, we remove stellar variability using a Gaussian Processes model fit to the out of transit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data and convert to parts per thousand\n",
    "x = np.ascontiguousarray(lc.time, dtype=np.float64)\n",
    "y = np.ascontiguousarray((lc.flux - 1.0) * 1e3, dtype=np.float64)\n",
    "yerr = np.ascontiguousarray(lc.flux_err * 1e3, dtype=np.float64)\n",
    "\n",
    "# Compute the transit mask\n",
    "mask = np.zeros_like(x, dtype=bool)\n",
    "for i in range(len(periods)):\n",
    "    mask |= get_transit_mask(x, t0s[i], periods[i], 5*durations[i])\n",
    "\n",
    "# Temporarily increase the in transit error bars substantially\n",
    "diag = np.array(yerr**2)\n",
    "diag[mask] *= 1000.0\n",
    "\n",
    "# Build a GP model\n",
    "with pm.Model() as model:\n",
    "    logs2 = pm.Normal(\"logs2\", mu=np.log(1e-4*np.var(y)), sd=10)\n",
    "    logsigma = pm.Normal(\"logsigma\", mu=np.log(np.std(y)), sd=10)\n",
    "    logrho = pm.Normal(\"logrho\", mu=np.log(10.0), sd=10.0)\n",
    "    \n",
    "    kernel = xo.gp.terms.Matern32Term(log_sigma=logsigma, log_rho=logrho)\n",
    "    gp = xo.gp.GP(kernel, x, diag + tt.exp(logs2), J=2)\n",
    "    pm.Potential(\"loglike\", gp.log_likelihood(y))\n",
    "    \n",
    "    map_soln = xo.optimize()\n",
    "    pred = xo.utils.eval_in_model(gp.predict(), map_soln)\n",
    "\n",
    "# Flatten the light curve\n",
    "y -= pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transit model in PyMC3 & exoplanet\n",
    "\n",
    "Here's how we set up the transit model using [exoplanet](https://exoplanet.dfm.io) and [PyMC3](https://docs.pymc.io).\n",
    "For more information about how to use these libraries take a look at the docs that are linked above.\n",
    "In this model, the parameters that we're fitting are:\n",
    "\n",
    "* `mean`: the mean flux of the star,\n",
    "* `u`: the quadratic limb darkening parameters, parameterized following [Kipping (2013)](https://arxiv.org/abs/1308.0009)\n",
    "* `t0`: the time of a reference transit for each planet,\n",
    "* `logP`: the log of the obribatl periods,\n",
    "* `r`: the planet radius ratios (relative to the star),\n",
    "* `b`: the impact parameter in units of the stellar radius, `b` and `r` are both parameterized following [Espinoza (2018)](https://iopscience.iop.org/article/10.3847/2515-5172/aaef38/meta), and\n",
    "* `logs2`: a jitter parameter that captures excess noise or underrestimated error bars.\n",
    "\n",
    "A few key assumptions include:\n",
    "\n",
    "* The orbits are assumed to be circular so the constraints on impact parameter (which would be severely degenerate with eccentricity) will be tighter than they should be.\n",
    "* The noise is assumed to be Gaussian and independent. This means that all correlated noise should be removed in advance. Since we flattened the light curve using a Gaussian process above, this should be not totally unreasonable.\n",
    "* We are neglecting transit times (the ephemeris is assumed to be linear) which should be sufficient for most cases with the short TESS baseline, but transit timing variations could be important for some targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x, y, yerr, periods, t0s, depths, mask=None, start=None):\n",
    "    \"\"\"Build an exoplanet model for a dataset and set of planets\n",
    "    \n",
    "    Args:\n",
    "        x: The time series (in days); this should probably be centered\n",
    "        y: The relative fluxes (in parts per thousand)\n",
    "        yerr: The uncertainties on ``y``\n",
    "        periods: The periods of the planets (in days)\n",
    "        t0s: The phases of the planets in the same coordinates as ``x``\n",
    "        depths: The depths of the transits in parts per thousand\n",
    "        mask: A boolean mask with the same shape as ``x`` indicating which\n",
    "            data points should be included in the fit\n",
    "        start: A dictionary of model parameters where the optimization\n",
    "            should be initialized\n",
    "            \n",
    "    Returns:\n",
    "        A PyMC3 model specifying the probabilistic model for the light curve\n",
    "\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        mask = np.ones(len(x), dtype=bool)\n",
    "    \n",
    "    periods = np.atleast_1d(periods)\n",
    "    t0s = np.atleast_1d(t0s)\n",
    "    depths = np.atleast_1d(depths)\n",
    "    n_planets = len(periods)\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        \n",
    "        # Extract the un-masked data points\n",
    "        model.x = x[mask]\n",
    "        model.y = y[mask]\n",
    "        model.yerr = (yerr + np.zeros_like(x))[mask]\n",
    "        model.mask = mask\n",
    "\n",
    "        # The baseline (out-of-transit) flux for the star in ppt. This\n",
    "        # should be close to one because of how we normalized the data\n",
    "        mean = pm.Normal(\"mean\", mu=0.0, sd=10.0)\n",
    "\n",
    "        # The time of a reference transit for each planet\n",
    "        t0 = pm.Normal(\"t0\", mu=t0s, sd=1.0, shape=n_planets)\n",
    "\n",
    "        # The log period; also tracking the period itself\n",
    "        logP = pm.Normal(\"logP\", mu=np.log(periods), sd=0.1, shape=n_planets)\n",
    "        period = pm.Deterministic(\"period\", tt.exp(logP))\n",
    "\n",
    "        # The Kipping (2013) parameterization for quadratic limb darkening paramters\n",
    "        u = xo.distributions.QuadLimbDark(\"u\")\n",
    "\n",
    "        # The Espinoza (2018) parameterization for the joint radius ratio and\n",
    "        # impact parameter distribution\n",
    "        r, b = xo.distributions.get_joint_radius_impact(\n",
    "            min_radius=0.001, max_radius=1.0,\n",
    "            testval_r=np.sqrt(1e-3*np.array(depths)),\n",
    "            testval_b=0.5+np.zeros(n_planets)\n",
    "        )\n",
    "\n",
    "        # This shouldn't make a huge difference, but I like to put a uniform\n",
    "        # prior on the *log* of the radius ratio instead of the value. This\n",
    "        # can be implemented by adding a custom \"potential\" (log probability).\n",
    "        pm.Potential(\"r_prior\", -pm.math.log(r))\n",
    "\n",
    "        # Set up a Keplerian orbit for the planets\n",
    "        model.orbit = xo.orbits.KeplerianOrbit(\n",
    "            period=period, t0=t0, b=b)\n",
    "        \n",
    "        # Compute the model light curve using starry\n",
    "        model.light_curves = xo.StarryLightCurve(u).get_light_curve(\n",
    "            orbit=model.orbit, r=r, t=model.x)\n",
    "        model.light_curve = pm.math.sum(model.light_curves, axis=-1) * 1e3 + mean\n",
    "\n",
    "        # Jitter and likelihood function\n",
    "        logs2 = pm.Normal(\"logs2\", mu=np.log(np.mean(model.yerr)), sd=10)\n",
    "        pm.Normal(\"obs\", mu=model.light_curve, sd=tt.sqrt(model.yerr**2+tt.exp(logs2)),\n",
    "                  observed=model.y)\n",
    "\n",
    "        # Fit for the maximum a posteriori parameters, I've found that I can get\n",
    "        # a better solution by trying different combinations of parameters in turn\n",
    "        if start is None:\n",
    "            start = model.test_point\n",
    "        map_soln = start        \n",
    "        map_soln = xo.optimize(start=map_soln, vars=[logs2, mean])\n",
    "        map_soln = xo.optimize(start=map_soln, vars=[model.rb, mean])\n",
    "        map_soln = xo.optimize(start=map_soln, vars=[logP, t0, mean])\n",
    "        map_soln = xo.optimize(start=map_soln, vars=[model.rb, mean])\n",
    "        map_soln = xo.optimize(start=map_soln)\n",
    "        model.map_soln = map_soln\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above function, we'll generate a probabilistic model for the light curve and plot the maximum a posteriori fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(x, y, yerr, periods, t0s, depths)\n",
    "\n",
    "with model:\n",
    "    mean = model.map_soln[\"mean\"]\n",
    "    light_curves = xo.utils.eval_in_model(model.light_curves, model.map_soln)\n",
    "\n",
    "plt.plot(model.x, model.y - mean, \"k\", label=\"data\")\n",
    "for n, l in enumerate(letters):\n",
    "    plt.plot(model.x, 1e3 * light_curves[:, n], label=\"planet {0}\".format(l), zorder=100-n)\n",
    "\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"flux [ppt]\")\n",
    "plt.title(\"initial fit\")\n",
    "plt.xlim(model.x.min(), model.x.max())\n",
    "plt.legend(fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "Now we use PyMC3 to sample the posterior density for the parameters of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "sampler = xo.PyMC3Sampler(window=50, start=50, finish=500)\n",
    "with model:\n",
    "    burnin = sampler.tune(tune=3000, start=model.map_soln,\n",
    "                          step_kwargs=dict(target_accept=0.9),\n",
    "                          chains=2)\n",
    "    trace = sampler.sample(draws=1000, chains=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the summary function to check convergence and report posterior means and variances for the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace, varnames=[\"mean\", \"u\", \"period\", \"t0\", \"r\", \"b\", \"logs2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then plot the posterior constraints on the folded transit models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    light_curves = np.empty((500, len(model.x), len(periods)))\n",
    "    func = xo.utils.get_theano_function_for_var(model.light_curves)\n",
    "    for i, sample in enumerate(xo.utils.get_samples_from_trace(\n",
    "            trace, size=len(light_curves))):\n",
    "        light_curves[i] = func(*xo.utils.get_args_for_theano_function(sample))\n",
    "\n",
    "for n, letter in enumerate(letters):\n",
    "    plt.figure()\n",
    "\n",
    "    # Compute the GP prediction\n",
    "    mean_mod = np.median(trace[\"mean\"][:, None])\n",
    "\n",
    "    # Get the posterior median orbital parameters\n",
    "    p = np.median(trace[\"period\"][:, n])\n",
    "    t0 = np.median(trace[\"t0\"][:, n])\n",
    "\n",
    "    # Compute the median of posterior estimate of the contribution from\n",
    "    # the other planet. Then we can remove this from the data to plot\n",
    "    # just the planet we care about.\n",
    "    inds = np.arange(len(periods)) != n\n",
    "    others = np.median(1e3*np.sum(light_curves[:, :, inds], axis=-1), axis=0)\n",
    "\n",
    "    # Plot the folded data\n",
    "    x_fold = (model.x - t0 + 0.5*p) % p - 0.5*p\n",
    "    plt.plot(x_fold, model.y - mean_mod - others, \".k\", label=\"data\", zorder=-1000)\n",
    "\n",
    "    # Plot the folded model\n",
    "    inds = np.argsort(x_fold)\n",
    "    inds = inds[np.abs(x_fold)[inds] < 0.3]\n",
    "    pred = 1e3 * light_curves[:, inds, n]\n",
    "    pred = np.percentile(pred, [16, 50, 84], axis=0)\n",
    "    plt.plot(x_fold[inds], pred[1], color=\"C1\", label=\"model\")\n",
    "    art = plt.fill_between(x_fold[inds], pred[0], pred[2], color=\"C1\", alpha=0.5,\n",
    "                           zorder=1000)\n",
    "    art.set_edgecolor(\"none\")\n",
    "\n",
    "    # Annotate the plot with the planet's period\n",
    "    txt = \"period = {0:.4f} +/- {1:.4f} d\".format(\n",
    "        np.mean(trace[\"period\"][:, n]), np.std(trace[\"period\"][:, n]))\n",
    "    plt.annotate(txt, (0, 0), xycoords=\"axes fraction\",\n",
    "                 xytext=(5, 5), textcoords=\"offset points\",\n",
    "                 ha=\"left\", va=\"bottom\", fontsize=12)\n",
    "\n",
    "    plt.legend(fontsize=10, loc=4)\n",
    "    plt.xlim(-0.5*p, 0.5*p)\n",
    "    plt.xlabel(\"time since transit [days]\")\n",
    "    plt.ylabel(\"de-trended flux\")\n",
    "    plt.title(\"TOI {0}{1}\".format(toi_num, letter));\n",
    "    plt.xlim(-0.3, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior constraints\n",
    "\n",
    "Given the MCMC sampling, we can make some plots summarizing the constraints on the key parameters.\n",
    "First up, we'll propagate the constraint on the radius ratio to a constraint on the physical radius of the planet using the stellar radius constraint from the TOI list (if provided).\n",
    "We also plot the impact parameter constraints on this plot (remember that we're using circular orbits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ror_samps = trace[\"r\"]\n",
    "r_star_samps = toi_r_star + toi_r_star_err * np.random.randn(len(ror_samps))\n",
    "r_pl = ror_samps * r_star_samps[:, None] * 109.07637070600963\n",
    "samples = np.concatenate((r_pl, trace[\"b\"]), axis=-1)\n",
    "\n",
    "labels = [\"$R_{{\\mathrm{{Pl}},{0}}}$ [$R_\\oplus$]\".format(i) for i in letters]\n",
    "labels += [\"impact param {0}\".format(i) for i in letters]\n",
    "\n",
    "corner.corner(samples, labels=labels,\n",
    "              show_titles=True, title_kwargs=dict(fontsize=10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other most interesting parameters are the period and transit times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"$P_{{{0}}}$ [days]\".format(i) for i in letters]\n",
    "labels += [\"$t0_{{{0}}}$ [TBJD]\".format(i) for i in letters]\n",
    "samples = np.concatenate((trace[\"period\"], trace[\"t0\"]), axis=-1)\n",
    "corner.corner(samples, labels=labels,\n",
    "              show_titles=True, title_fmt=\".5f\",\n",
    "              title_kwargs=dict(fontsize=10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution\n",
    "\n",
    "If you use these results or this code, please consider citing the relevant sources.\n",
    "First, you can [cite the lightkurve package](https://zenodo.org/record/2611871):\n",
    "\n",
    "```bibtex\n",
    "@misc{lightkurve,\n",
    "  author       = {Geert Barentsen and\n",
    "                  Christina Hedges and\n",
    "                  Zé Vinícius and\n",
    "                  Nicholas Saunders and\n",
    "                  gully and\n",
    "                  Oliver Hall and\n",
    "                  Sheila Sagear and\n",
    "                  Tom Barclay and\n",
    "                  KenMighell and\n",
    "                  Keaton Bell and\n",
    "                  Johnny Zhang and\n",
    "                  Emma Turtelboom and\n",
    "                  Zach Berta-Thompson and\n",
    "                  Peter Williams and\n",
    "                  Jose A Lerma III and\n",
    "                  Guy Davies and\n",
    "                  Brennan Vincello and\n",
    "                  Anand Sundaram},\n",
    "  title        = {KeplerGO/lightkurve: Lightkurve v1.0b30},\n",
    "  month        = mar,\n",
    "  year         = 2019,\n",
    "  doi          = {10.5281/zenodo.2611871},\n",
    "  url          = {https://doi.org/10.5281/zenodo.2611871}\n",
    "}\n",
    "```\n",
    "\n",
    "You can also [cite the exoplanet project and its dependencies](https://exoplanet.dfm.io/en/stable/tutorials/citation/) using the following acknowledgement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    txt, bib = xo.citations.get_citations_for_model()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and BibTeX entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "This notebook was run with the following conda environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
